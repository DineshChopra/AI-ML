{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9_Padding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfqJCa0wAqwOVbDdFM3+UE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DineshChopra/AI-ML/blob/master/TensorFlow/Udacity/NLP/9_Padding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP5XdV1sEb5c"
      },
      "source": [
        "# Preparing text to use TensorFlow models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbDsn9AIEtn0"
      },
      "source": [
        "The high level steps to prepare text to be used in a machine learning model are:\n",
        "\n",
        "1. Tokenize the words to get numerical values for them\n",
        "2. Create numerical sequences of the sentences\n",
        "3. Adjust the sequences to all be the same length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S1VdvkvE4Ho"
      },
      "source": [
        "## Import the classes you need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrrWalrpEE94"
      },
      "source": [
        "# Import Tokenizer and pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF_DnkLlFQjN"
      },
      "source": [
        "## Write some sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd2hQ6gUFTny",
        "outputId": "9dec07da-96cf-4f7a-8646-2016fa68a1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sentences = [\n",
        "    'My favorite food is ice cream',\n",
        "    'do you like ice cream too?',\n",
        "    'My dog likes ice cream!',\n",
        "    \"your favorite flavor of icecream is chocolate\",\n",
        "    \"chocolate isn't good for dogs\",\n",
        "    \"your dog, your cat, and your parrot prefer broccoli\"\n",
        "]\n",
        "print(sentences)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My favorite food is ice cream', 'do you like ice cream too?', 'My dog likes ice cream!', 'your favorite flavor of icecream is chocolate', \"chocolate isn't good for dogs\", 'your dog, your cat, and your parrot prefer broccoli']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2ensP7bFkI6"
      },
      "source": [
        "## Create the Tokenizer and define an out of vocabulary token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Wq1V72FrxY"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6u1nUL3F3g4"
      },
      "source": [
        "## Tokenize the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbmbQFzJF6jy",
        "outputId": "837b8451-2234-4693-e3c9-e85207b700a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Y0XKAmGaj7"
      },
      "source": [
        "## Turn sentences into Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xPVfaIFGt35",
        "outputId": "1ea3468c-1c6c-40fe-bfee-a38b64e61e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GSssF00G-pU"
      },
      "source": [
        "## Make the sequences all the same length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqQx5ctoHEUF",
        "outputId": "37c11217-087f-4449-86f9-cff958d7621f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "padded = pad_sequences(sequences)\n",
        "print(\"\\n Word Index = \", word_index)\n",
        "print(\"\\n Sequences = \", sequences)\n",
        "print(\"\\n Padded Sequences:\")\n",
        "print(padded)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Word Index =  {'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n",
            "\n",
            " Sequences =  [[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n",
            "\n",
            " Padded Sequences:\n",
            "[[ 0  0  0  5  6 10  7  3  4]\n",
            " [ 0  0  0 11 12 13  3  4 14]\n",
            " [ 0  0  0  0  5  8 15  3  4]\n",
            " [ 0  0  2  6 16 17 18  7  9]\n",
            " [ 0  0  0  0  9 19 20 21 22]\n",
            " [ 2  8  2 23 24  2 25 26 27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtpATRyjHjso",
        "outputId": "6c60eff5-c065-4ab1-95f7-0e7a2ce2b520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Specify a max length for the padded sequences\n",
        "padded = pad_sequences(sequences, maxlen=15)\n",
        "print(padded)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  5  6 10  7  3  4]\n",
            " [ 0  0  0  0  0  0  0  0  0 11 12 13  3  4 14]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  5  8 15  3  4]\n",
            " [ 0  0  0  0  0  0  0  0  2  6 16 17 18  7  9]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  9 19 20 21 22]\n",
            " [ 0  0  0  0  0  0  2  8  2 23 24  2 25 26 27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Es_loNHwos",
        "outputId": "dd12098b-dae6-4a3c-f837-f8e663b87904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Put the padding at the end of the sequences\n",
        "padded = pad_sequences(sequences, maxlen=15, padding='post')\n",
        "print(padded)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5  6 10  7  3  4  0  0  0  0  0  0  0  0  0]\n",
            " [11 12 13  3  4 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  8 15  3  4  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  6 16 17 18  7  9  0  0  0  0  0  0  0  0]\n",
            " [ 9 19 20 21 22  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  8  2 23 24  2 25 26 27  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtkLrWCKIKDK",
        "outputId": "26d63497-3ece-48dc-bbe5-51441b54b21c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Limit the length of the sequences, you will see some sequences get truncated\n",
        "padded = pad_sequences(sequences, maxlen=5)\n",
        "print(padded)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6 10  7  3  4]\n",
            " [12 13  3  4 14]\n",
            " [ 5  8 15  3  4]\n",
            " [16 17 18  7  9]\n",
            " [ 9 19 20 21 22]\n",
            " [24  2 25 26 27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXKsgOo9IwX4",
        "outputId": "879403d6-885f-4d77-b266-e371c2eba677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Limit the length of the sequences, you will see some sequences get truncated in post manner\n",
        "padded = pad_sequences(sequences, maxlen=5, truncating='post')\n",
        "print(padded)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5  6 10  7  3]\n",
            " [11 12 13  3  4]\n",
            " [ 5  8 15  3  4]\n",
            " [ 2  6 16 17 18]\n",
            " [ 9 19 20 21 22]\n",
            " [ 2  8  2 23 24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2rIxHorI9cF"
      },
      "source": [
        "## What happens if some of the sentences contain words that are not in the word index?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrbqTcXdJbpg"
      },
      "source": [
        "Here's where the \"out of vocabulary\" token is used. Try generating sequences for same sentences that have words that are not in the word index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt8UK2jqJEpY",
        "outputId": "682e8f0c-0097-4915-87ef-d1cfe8c6ed2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Try turning sentences that contain words that \n",
        "# are't in the word index into sequences.\n",
        "# Add your own sentences to the test_data\n",
        "test_data = [\n",
        "  \"my best friend's favorite ice cream flavor is strawberry\",\n",
        "  \"my dog's best friend is a manatee\"\n",
        "]\n",
        "print(test_data)\n",
        "\n",
        "# Remind ourselves which number corresponds to the \n",
        "# out of vocabulary token in the word index\n",
        "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"my best friend's favorite ice cream flavor is strawberry\", \"my dog's best friend is a manatee\"]\n",
            "<OOV> has the number 1 in the word index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE50ZPuwKwJy",
        "outputId": "0c62778f-91dc-4255-b549-2c006f64931e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Convert the test sentences to sequences\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Sequence =  [[5, 1, 1, 6, 3, 4, 16, 7, 1], [5, 1, 1, 1, 7, 1, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihB9SVu3LM3O",
        "outputId": "7fb9dba5-da7e-414f-d926-9b74acb2e158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Pad the new sequence\n",
        "padded = pad_sequences(test_seq, maxlen=10)\n",
        "print(\"\\n Padded Test Sequence: \")\n",
        "\n",
        "# Notice that \"1\" appears in the sequence wherever there's a word \n",
        "# that's not in the word index\n",
        "print(\"\\n\", padded)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Padded Test Sequence: \n",
            "\n",
            " [[ 0  5  1  1  6  3  4 16  7  1]\n",
            " [ 0  0  0  5  1  1  1  7  1  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}